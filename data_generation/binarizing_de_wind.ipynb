{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a2e5e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import os\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d81759b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dati iniziali caricati con successo dai file .pkl.\n",
      "Dati binari generati e nuova struttura del dizionario creata.\n",
      "Assicurata l'esistenza della directory: /home/student/Desktop/Groundeep/circle_dataset_100x100/\n",
      "Nuovi dati di train (con labels e idxs) salvati in: /home/student/Desktop/Groundeep/circle_dataset_100x100/binary_de_wind_train.pkl\n",
      "Nuovi dati di test (con labels e idxs) salvati in: /home/student/Desktop/Groundeep/circle_dataset_100x100/binary_de_wind_test.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import os\n",
    "import torch # Necessario perché 'data_train' e 'data_test' contengono tensori PyTorch\n",
    "\n",
    "# Caricamento dei dati dai file .pkl esistenti\n",
    "# Abbiamo visto che questi contengono tensori PyTorch, quindi pkl.load funziona\n",
    "# ma l'output 'data' è un tensore PyTorch\n",
    "with open('/home/student/Desktop/Groundeep/pairs_from_mat_train.pkl', 'rb') as f:\n",
    "    data_train = pkl.load(f)\n",
    "\n",
    "with open('/home/student/Desktop/Groundeep/pairs_from_mat_test.pkl', 'rb') as f:\n",
    "    data_test = pkl.load(f)\n",
    "\n",
    "print(\"Dati iniziali caricati con successo dai file .pkl.\")\n",
    "# Esempio di come appare data_train:\n",
    "# {'data': tensor([...]), 'labels': tensor([...]), 'idxs': tensor([...])}\n",
    "\n",
    "\n",
    "# --- Modifica qui per convertire solo i dati in binario e mantenere la struttura ---\n",
    "\n",
    "# Converti i tensori 'data' in NumPy array per l'operazione np.where\n",
    "# Assicurati di usare .cpu().numpy() se stai lavorando con GPU\n",
    "data_np_train = data_train['data'].cpu().numpy()\n",
    "data_np_test = data_test['data'].cpu().numpy()\n",
    "\n",
    "# Esegui l'operazione binaria sull'array NumPy\n",
    "binary_data_np_train = np.where(data_np_train >= 0.5, 255, 0).astype(np.uint8)\n",
    "binary_data_np_test = np.where(data_np_test >= 0.5, 255, 0).astype(np.uint8)\n",
    "\n",
    "# Crea nuovi dizionari che contengono i dati binari e le chiavi originali\n",
    "# Converti i tensori originali 'labels' e 'idxs' in NumPy array\n",
    "# per coerenza nel nuovo file .pkl, se desideri che tutto sia NumPy\n",
    "# o lasciali come tensori se prevedi di ricaricarli con PyTorch in seguito.\n",
    "# Per semplicità e coispicuità con numpy.where, li converto a numpy.\n",
    "new_data_train = {\n",
    "    'data': binary_data_np_train,\n",
    "    'labels': data_train['labels'].cpu().numpy(),\n",
    "    'idxs': data_train['idxs'].cpu().numpy()\n",
    "}\n",
    "\n",
    "new_data_test = {\n",
    "    'data': binary_data_np_test,\n",
    "    'labels': data_test['labels'].cpu().numpy(),\n",
    "    'idxs': data_test['idxs'].cpu().numpy()\n",
    "}\n",
    "\n",
    "print(\"Dati binari generati e nuova struttura del dizionario creata.\")\n",
    "\n",
    "\n",
    "# --- Sezione per il salvataggio dei file .pkl ---\n",
    "\n",
    "# Definisci la directory di output\n",
    "output_dir = '/home/student/Desktop/Groundeep/circle_dataset_100x100/'\n",
    "\n",
    "# Crea la directory di output se non esiste\n",
    "try:\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Assicurata l'esistenza della directory: {output_dir}\")\n",
    "except OSError as e:\n",
    "    print(f\"Errore nella creazione della directory {output_dir}: {e}\")\n",
    "    print(\"Controlla i permessi o il percorso.\")\n",
    "    exit()\n",
    "\n",
    "# Definisci i percorsi completi per i nuovi file .pkl\n",
    "output_path_train_pkl = os.path.join(output_dir, 'binary_de_wind_train.pkl')\n",
    "output_path_test_pkl = os.path.join(output_dir, 'binary_de_wind_test.pkl')\n",
    "\n",
    "# Salvataggio dei nuovi dizionari come file .pkl\n",
    "try:\n",
    "    with open(output_path_train_pkl, 'wb') as f:\n",
    "        pkl.dump(new_data_train, f) # Salva il nuovo dizionario\n",
    "    print(f\"Nuovi dati di train (con labels e idxs) salvati in: {output_path_train_pkl}\")\n",
    "except Exception as e:\n",
    "    print(f\"Errore durante il salvataggio del file di train: {e}\")\n",
    "    print(\"Verifica i permessi di scrittura e lo spazio su disco.\")\n",
    "\n",
    "try:\n",
    "    with open(output_path_test_pkl, 'wb') as f:\n",
    "        pkl.dump(new_data_test, f) # Salva il nuovo dizionario\n",
    "    print(f\"Nuovi dati di test (con labels e idxs) salvati in: {output_path_test_pkl}\")\n",
    "except Exception as e:\n",
    "    print(f\"Errore durante il salvataggio del file di test: {e}\")\n",
    "    print(\"Verifica i permessi di scrittura e lo spazio su disco.\")\n",
    "\n",
    "# --- Le righe originali per salvare come .npz (se vuoi mantenerle, altrimenti rimuovile) ---\n",
    "# np.savez(os.path.join(output_dir, 'binary_de_wind_train.npz'), data=binary_data_np_train)\n",
    "# np.savez(os.path.join(output_dir, 'binary_de_wind_test.npz'), data=binary_data_np_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "267a2c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(659, 100, 10000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load('/home/student/Desktop/Groundeep/circle_dataset_100x100/binary_de_wind.npz')\n",
    "\n",
    "data = data['binary_data']\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fb21086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dati binari generati e nuova struttura del dizionario creata.\n",
      "Assicurata l'esistenza della directory: /home/student/Desktop/Groundeep/circle_dataset_100x100/\n",
      "Errore durante il salvataggio del file di train: name 'output_path_train_pkl' is not defined\n",
      "Verifica i permessi di scrittura e lo spazio su disco.\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import os\n",
    "import torch # Necessario perché 'data_train' e 'data_test' contengono tensori PyTorch\n",
    "\n",
    "# Caricamento dei dati dai file .pkl esistenti\n",
    "# Abbiamo visto che questi contengono tensori PyTorch, quindi pkl.load funziona\n",
    "# ma l'output 'data' è un tensore PyTorch\n",
    "data = np.load(\"/home/student/Desktop/Groundeep/circle_dataset_100x100/circle_dataset_100x100_v2.npz\")\n",
    "# --- Modifica qui per convertire solo i dati in binario e mantenere la struttura ---\n",
    "\n",
    "# Converti i tensori 'data' in NumPy array per l'operazione np.where\n",
    "# Assicurati di usare .cpu().numpy() se stai lavorando con GPU\n",
    "\n",
    "# Esegui l'operazione binaria sull'array NumPy\n",
    "binary_data = np.where(data['D'] >= 0.5, 255, 0).astype(np.uint8)\n",
    "\n",
    "# Crea nuovi dizionari che contengono i dati binari e le chiavi originali\n",
    "# Converti i tensori originali 'labels' e 'idxs' in NumPy array\n",
    "# per coerenza nel nuovo file .pkl, se desideri che tutto sia NumPy\n",
    "# o lasciali come tensori se prevedi di ricaricarli con PyTorch in seguito.\n",
    "# Per semplicità e coispicuità con numpy.where, li converto a numpy.\n",
    "new_data_train = {\n",
    "    'D': binary_data,\n",
    "    'N_list': data['N_list'],\n",
    "    'cumArea_list': data['cumArea_list'],\n",
    "    'FA_list': data['FA_list'],\n",
    "    'CH_list': data['CH_list'],\n",
    "    'item_size': data['item_size']\n",
    "}\n",
    "\n",
    "print(\"Dati binari generati e nuova struttura del dizionario creata.\")\n",
    "\n",
    "\n",
    "# --- Sezione per il salvataggio dei file .pkl ---\n",
    "\n",
    "# Definisci la directory di output\n",
    "output_dir = '/home/student/Desktop/Groundeep/circle_dataset_100x100/'\n",
    "\n",
    "# Crea la directory di output se non esiste\n",
    "try:\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Assicurata l'esistenza della directory: {output_dir}\")\n",
    "except OSError as e:\n",
    "    print(f\"Errore nella creazione della directory {output_dir}: {e}\")\n",
    "    print(\"Controlla i permessi o il percorso.\")\n",
    "    exit()\n",
    "\n",
    "# Definisci i percorsi completi per i nuovi file .pkl\n",
    "output_path = os.path.join(output_dir, 'binarized_data.npz')\n",
    "\n",
    "# Salvataggio dei nuovi dizionari come file .pkl\n",
    "try:\n",
    "    np.savez(output_path,**new_data_train)# Salva il nuovo dizionario\n",
    "    print(f\"Nuovi dati di train (con labels e idxs) salvati in: {output_path_train_pkl}\")\n",
    "except Exception as e:\n",
    "    print(f\"Errore durante il salvataggio del file di train: {e}\")\n",
    "    print(\"Verifica i permessi di scrittura e lo spazio su disco.\")\n",
    "\n",
    "\n",
    "# --- Le righe originali per salvare come .npz (se vuoi mantenerle, altrimenti rimuovile) ---\n",
    "# np.savez(os.path.join(output_dir, 'binary_de_wind_train.npz'), data=binary_data_np_train)\n",
    "# np.savez(os.path.join(output_dir, 'binary_de_wind_test.npz'), data=binary_data_np_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66dbe3a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cb7274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "groundeep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
